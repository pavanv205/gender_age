{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kScKRktUHK0",
        "outputId": "6429b477-a16a-4c12-da79-fb71aa9115dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading IMDB-WIKI subset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: 774MB [00:37, 20.75MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted dataset.\n",
            "Processing .mat label file...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2-2445232699.py:54: RuntimeWarning: overflow encountered in scalar subtract\n",
            "  age = photo_taken[i] - datetime.fromordinal(int(dob[i])).year\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved full_labels.csv with 5000 samples.\n",
            "Resizing images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [00:10<00:00, 467.63it/s]\n",
            "Epoch 1 - Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:06<00:00, 10.86it/s]\n",
            "Epoch 1 - Val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 16.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss = 533.7124, Val Loss = 340.5427\n",
            "ðŸ“¦ Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 - Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:04<00:00, 17.36it/s]\n",
            "Epoch 2 - Val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 15.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train Loss = 309.1904, Val Loss = 308.5546\n",
            "ðŸ“¦ Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 - Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:04<00:00, 17.59it/s]\n",
            "Epoch 3 - Val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 11.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train Loss = 298.2868, Val Loss = 291.3585\n",
            "ðŸ“¦ Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 - Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:05<00:00, 13.12it/s]\n",
            "Epoch 4 - Val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 16.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss = 294.4931, Val Loss = 282.2455\n",
            "ðŸ“¦ Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 - Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:03<00:00, 17.76it/s]\n",
            "Epoch 5 - Val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 16.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss = 282.8377, Val Loss = 275.2137\n",
            "ðŸ“¦ Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 - Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:04<00:00, 15.38it/s]\n",
            "Epoch 6 - Val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  9.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train Loss = 279.4037, Val Loss = 273.1553\n",
            "ðŸ“¦ Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 - Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:04<00:00, 15.68it/s]\n",
            "Epoch 7 - Val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 16.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train Loss = 278.6101, Val Loss = 282.6181\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 - Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:04<00:00, 17.66it/s]\n",
            "Epoch 8 - Val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 15.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train Loss = 273.5891, Val Loss = 276.2077\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 - Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:05<00:00, 13.60it/s]\n",
            "Epoch 9 - Val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 12.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train Loss = 271.4840, Val Loss = 271.1701\n",
            "ðŸ“¦ Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 - Train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:04<00:00, 17.07it/s]\n",
            "Epoch 10 - Val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00, 15.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train Loss = 274.4053, Val Loss = 271.1621\n",
            "ðŸ“¦ Saved best model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import scipy.io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import tarfile\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ========== CONFIG ==========\n",
        "DATA_DIR = 'data'\n",
        "IMG_SIZE = 128\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "LR = 1e-3\n",
        "MODEL_PATH = '/content/drive/MyDrive/best_age_model.pth'\n",
        "LIMIT_IMAGES = 5000  # use smaller dataset for testing\n",
        "# ============================\n",
        "\n",
        "# ---------- Step 1: Download ----------\n",
        "def download_dataset():\n",
        "    url = \"https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/static/wiki_crop.tar\"\n",
        "    os.makedirs(DATA_DIR, exist_ok=True)\n",
        "    tar_path = os.path.join(DATA_DIR, \"wiki_crop.tar\")\n",
        "    if not os.path.exists(tar_path):\n",
        "        print(\"Downloading IMDB-WIKI subset...\")\n",
        "        with requests.get(url, stream=True) as r:\n",
        "            with open(tar_path, 'wb') as f:\n",
        "                for chunk in tqdm(r.iter_content(1024*1024), desc=\"Downloading\", unit=\"MB\"):\n",
        "                    f.write(chunk)\n",
        "    with tarfile.open(tar_path) as tar:\n",
        "        tar.extractall(DATA_DIR)\n",
        "        print(\"Extracted dataset.\")\n",
        "\n",
        "# ---------- Step 2: Preprocess ----------\n",
        "def extract_labels():\n",
        "    print(\"Processing .mat label file...\")\n",
        "    mat = scipy.io.loadmat(os.path.join(DATA_DIR, \"wiki_crop/wiki.mat\"))\n",
        "    mat = mat['wiki'][0, 0]\n",
        "    full_path = mat['full_path'][0]\n",
        "    dob = mat['dob'][0]\n",
        "    photo_taken = mat['photo_taken'][0]\n",
        "\n",
        "    ages = []\n",
        "    filenames = []\n",
        "    for i in range(len(full_path)):\n",
        "        age = photo_taken[i] - datetime.fromordinal(int(dob[i])).year\n",
        "        if 0 < age <= 100:\n",
        "            ages.append(age)\n",
        "            filenames.append(full_path[i][0])\n",
        "        if len(filenames) >= LIMIT_IMAGES:\n",
        "            break\n",
        "\n",
        "    df = pd.DataFrame({'filename': filenames, 'age': ages})\n",
        "    df.to_csv(os.path.join(DATA_DIR, 'full_labels.csv'), index=False)\n",
        "    print(f\"Saved full_labels.csv with {len(df)} samples.\")\n",
        "\n",
        "    resize_and_copy(df)\n",
        "\n",
        "def resize_and_copy(df):\n",
        "    src_folder = os.path.join(DATA_DIR, 'wiki_crop')\n",
        "    dst_folder = os.path.join(DATA_DIR, 'images')\n",
        "    os.makedirs(dst_folder, exist_ok=True)\n",
        "    print(\"Resizing images...\")\n",
        "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
        "        src = os.path.join(src_folder, row['filename'])\n",
        "        dst = os.path.join(dst_folder, f\"{i}.jpg\")\n",
        "        try:\n",
        "            img = Image.open(src).convert('RGB').resize((IMG_SIZE, IMG_SIZE))\n",
        "            img.save(dst)\n",
        "        except:\n",
        "            continue\n",
        "        df.at[i, 'filename'] = f\"{i}.jpg\"\n",
        "    df.to_csv(os.path.join(DATA_DIR, 'full_labels.csv'), index=False)\n",
        "\n",
        "# ---------- Step 3: Dataset ----------\n",
        "class AgeDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_path = os.path.join(self.img_dir, row['filename'])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        age = torch.tensor(row['age'], dtype=torch.float32)  # FIX: ensure float32\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, age\n",
        "\n",
        "# ---------- Step 4: Model ----------\n",
        "class SimpleAgeCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(self.cnn(x)).squeeze(1)\n",
        "\n",
        "# ---------- Step 5: Training ----------\n",
        "def train_model():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    df = pd.read_csv(os.path.join(DATA_DIR, 'full_labels.csv'))\n",
        "    train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "    train_df.to_csv(os.path.join(DATA_DIR, 'train_labels.csv'), index=False)\n",
        "    val_df.to_csv(os.path.join(DATA_DIR, 'val_labels.csv'), index=False)\n",
        "\n",
        "    train_dataset = AgeDataset(os.path.join(DATA_DIR, 'train_labels.csv'), os.path.join(DATA_DIR, 'images'), transform)\n",
        "    val_dataset = AgeDataset(os.path.join(DATA_DIR, 'val_labels.csv'), os.path.join(DATA_DIR, 'images'), transform)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "    model = SimpleAgeCNN().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for imgs, ages in tqdm(train_loader, desc=f\"Epoch {epoch} - Train\"):\n",
        "            imgs, ages = imgs.to(device), ages.to(device)\n",
        "            preds = model(imgs)\n",
        "            loss = criterion(preds, ages)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, ages in tqdm(val_loader, desc=f\"Epoch {epoch} - Val\"):\n",
        "                imgs, ages = imgs.to(device), ages.to(device)\n",
        "                preds = model(imgs)\n",
        "                loss = criterion(preds, ages)\n",
        "                total_val_loss += loss.item() * imgs.size(0)\n",
        "\n",
        "        avg_train = total_train_loss / len(train_dataset)\n",
        "        avg_val = total_val_loss / len(val_dataset)\n",
        "        print(f\"Epoch {epoch}: Train Loss = {avg_train:.4f}, Val Loss = {avg_val:.4f}\")\n",
        "\n",
        "        if avg_val < best_val_loss:\n",
        "            best_val_loss = avg_val\n",
        "            torch.save(model.state_dict(), MODEL_PATH)\n",
        "            print(\"ðŸ“¦ Saved best model\")\n",
        "\n",
        "# ---------- Run All ----------\n",
        "if __name__ == '__main__':\n",
        "    download_dataset()\n",
        "    extract_labels()\n",
        "    train_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(\"Current working directory:\", os.getcwd())\n"
      ],
      "metadata": {
        "id": "jGLbyKANUUvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4507173c-81b0-43d0-865c-6530d88a5e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model_path=MODEL_PATH, tolerance=5):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    val_dataset = AgeDataset(\n",
        "        os.path.join(DATA_DIR, 'val_labels.csv'),\n",
        "        os.path.join(DATA_DIR, 'images'),\n",
        "        transform=transform\n",
        "    )\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "    model = SimpleAgeCNN().to(device)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    mae = 0\n",
        "    total = 0\n",
        "    within_tol = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, ages in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            imgs, ages = imgs.to(device), ages.to(device)\n",
        "            preds = model(imgs)\n",
        "            error = torch.abs(preds - ages)\n",
        "            mae += error.sum().item()\n",
        "            within_tol += (error <= tolerance).sum().item()\n",
        "            total += imgs.size(0)\n",
        "\n",
        "    mae /= total\n",
        "    acc_tol = within_tol / total * 100\n",
        "    print(f\"\\nðŸ“Š MAE: {mae:.2f} years\")\n",
        "    print(f\"ðŸŽ¯ Accuracy within Â±{tolerance} years: {acc_tol:.2f}%\")\n"
      ],
      "metadata": {
        "id": "A4eH5WpE276Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model()\n"
      ],
      "metadata": {
        "id": "LI69IT2sAt6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0782a54-6e70-4f2a-cd45-9520dfdc411f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:00<00:00,  8.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š MAE: 13.20 years\n",
            "ðŸŽ¯ Accuracy within Â±5 years: 20.40%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "def age_to_class(age):\n",
        "    return min(age // 10, 9)  # Cap at class 9 (for ages >= 90)\n",
        "\n",
        "def evaluate_classification(model_path=MODEL_PATH):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    dataset = AgeDataset(\n",
        "        csv_file=os.path.join(DATA_DIR, 'val_labels.csv'),\n",
        "        img_dir=os.path.join(DATA_DIR, 'images'),\n",
        "        transform=transform\n",
        "    )\n",
        "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    model = SimpleAgeCNN().to(device)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, ages in tqdm(loader, desc=\"Evaluating Classification\"):\n",
        "            imgs = imgs.to(device)\n",
        "            preds = model(imgs).cpu().numpy()\n",
        "            true_ages = ages.numpy()\n",
        "\n",
        "            y_true.extend([age_to_class(a) for a in true_ages])\n",
        "            y_pred.extend([age_to_class(p) for p in preds])\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"ðŸŽ¯ Accuracy:  {acc:.4f}\")\n",
        "    print(f\"ðŸŽ¯ Precision: {precision:.4f}\")\n",
        "    print(f\"ðŸŽ¯ Recall:    {recall:.4f}\")\n",
        "    print(f\"ðŸŽ¯ F1 Score:  {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "cQDGwHPmBr_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_classification()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTS7x2sTCCJq",
        "outputId": "92726a5c-e190-47f1-cc51-b01da85cb279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Classification: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  7.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Accuracy:  0.2220\n",
            "ðŸŽ¯ Precision: 0.3477\n",
            "ðŸŽ¯ Recall:    0.2220\n",
            "ðŸŽ¯ F1 Score:  0.1359\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cGf2boSoCFi4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}